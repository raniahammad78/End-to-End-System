{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from openai) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from openai) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from requests>=2.20->openai) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from requests>=2.20->openai) (3.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from requests>=2.20->openai) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from requests>=2.20->openai) (2024.8.30)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from aiohttp->openai) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from aiohttp->openai) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from aiohttp->openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from aiohttp->openai) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from aiohttp->openai) (1.11.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\yn\\onedrive\\desktop\\building systems with the chatgpt api\\chatbot_env\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"esms-options\">{\"shimMode\": true}</script><style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n  const py_version = '3.5.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  const reloading = false;\n  const Bokeh = root.Bokeh;\n\n  // Set a timeout for this load but only if we are not already initializing\n  if (typeof (root._bokeh_timeout) === \"undefined\" || (force || !root._bokeh_is_initializing)) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      // Don't load bokeh if it is still initializing\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    } else if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      // There is nothing to load\n      run_callbacks();\n      return null;\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error(e) {\n      const src_el = e.srcElement\n      console.error(\"failed to load \" + (src_el.href || src_el.src));\n    }\n\n    const skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {}, 'shim': {}});\n      root._bokeh_is_loading = css_urls.length + 0;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    const existing_stylesheets = []\n    const links = document.getElementsByTagName('link')\n    for (let i = 0; i < links.length; i++) {\n      const link = links[i]\n      if (link.href != null) {\n        existing_stylesheets.push(link.href)\n      }\n    }\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const escaped = encodeURI(url)\n      if (existing_stylesheets.indexOf(escaped) !== -1) {\n        on_load()\n        continue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    var existing_scripts = []\n    const scripts = document.getElementsByTagName('script')\n    for (let i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n        existing_scripts.push(script.src)\n      }\n    }\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (let i = 0; i < js_modules.length; i++) {\n      const url = js_modules[i];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) !== -1 || existing_scripts.indexOf(escaped) !== -1) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      const url = js_exports[name];\n      const escaped = encodeURI(url)\n      if (skip.indexOf(escaped) >= 0 || root[name] != null) {\n        if (!window.requirejs) {\n          on_load();\n        }\n        continue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.holoviz.org/panel/1.5.0/dist/bundled/reactiveesm/es-module-shims@^1.10.0/dist/es-module-shims.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.5.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.5.2.min.js\", \"https://cdn.holoviz.org/panel/1.5.0/dist/panel.min.js\"];\n  const js_modules = [];\n  const js_exports = {};\n  const css_urls = [];\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (let i = 0; i < inline_js.length; i++) {\n        try {\n          inline_js[i].call(root, root.Bokeh);\n        } catch(e) {\n          if (!reloading) {\n            throw e;\n          }\n        }\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n        var NewBokeh = root.Bokeh;\n        if (Bokeh.versions === undefined) {\n          Bokeh.versions = new Map();\n        }\n        if (NewBokeh.version !== Bokeh.version) {\n          Bokeh.versions.set(NewBokeh.version, NewBokeh)\n        }\n        root.Bokeh = Bokeh;\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      // If the timeout and bokeh was not successfully loaded we reset\n      // everything and try loading again\n      root._bokeh_timeout = Date.now() + 5000;\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      root._bokeh_is_loading = 0\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      const bokeh_loaded = root.Bokeh != null && (root.Bokeh.version === py_version || (root.Bokeh.versions !== undefined && root.Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n        if (root.Bokeh) {\n          root.Bokeh = undefined;\n        }\n        console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n        console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n        run_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n",
      "application/vnd.holoviews_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='d6fc9dcb-8768-4577-bb01-ddd8fc502f2a'>\n",
       "  <div id=\"d809bccf-5be0-4085-8a2c-cfe327f61fc6\" data-root-id=\"d6fc9dcb-8768-4577-bb01-ddd8fc502f2a\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"2c0ffa4b-84c7-4192-82bf-6d21ab51d4e1\":{\"version\":\"3.5.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"d6fc9dcb-8768-4577-bb01-ddd8fc502f2a\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"a397363b-e300-42d0-8b77-844daf5e7335\",\"attributes\":{\"plot_id\":\"d6fc9dcb-8768-4577-bb01-ddd8fc502f2a\",\"comm_id\":\"21e832eb4cb24f09b2e5fbb88b66e59f\",\"client_comm_id\":\"12b2183806044f419aa80a799a79d1a6\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"gap\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"TemplateEditor1\",\"properties\":[{\"name\":\"layout\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"ReactiveESM1\"},{\"type\":\"model\",\"name\":\"JSComponent1\"},{\"type\":\"model\",\"name\":\"ReactComponent1\"},{\"type\":\"model\",\"name\":\"AnyWidgetComponent1\"},{\"type\":\"model\",\"name\":\"request_value1\",\"properties\":[{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"},{\"name\":\"_synced\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_request_sync\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"2c0ffa4b-84c7-4192-82bf-6d21ab51d4e1\",\"roots\":{\"d6fc9dcb-8768-4577-bb01-ddd8fc502f2a\":\"d809bccf-5be0-4085-8a2c-cfe327f61fc6\"},\"root_ids\":[\"d6fc9dcb-8768-4577-bb01-ddd8fc502f2a\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  async function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    await Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && id_el.children[0].hasAttribute('data-root-id')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t  for (const child of root_el.children) {\n",
       "            // Ensure JupyterLab does not capture keyboard shortcuts\n",
       "            // see: https://jupyterlab.readthedocs.io/en/4.1.x/extension/notebook.html#keyboard-interaction-model\n",
       "\t    child.setAttribute('data-lm-suppress-shortcuts', 'true')\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "d6fc9dcb-8768-4577-bb01-ddd8fc502f2a"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import utils\n",
    "\n",
    "import panel as pn  # GUI\n",
    "pn.extension()\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key  = os.environ['openai.api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=500):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, \n",
    "        max_tokens=max_tokens, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "System of chained prompts for processing the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_user_message(user_input, all_messages, debug=True):\n",
    "    delimiter = \"```\"\n",
    "    response = openai.Moderation.create(input=user_input)\n",
    "    moderation_output = response[\"results\"][0]\n",
    "    if moderation_output[\"flagged\"]:\n",
    "        print(\"Step 1: Input flagged by Moderation API.\")\n",
    "        return \"Sorry, we cannot process this request.\"\n",
    "    if debug: print(\"Step 1: Input passed moderation check.\")\n",
    "    category_and_product_response = utils.find_category_and_product_only(user_input, utils.get_products_and_category())\n",
    "    category_and_product_list = utils.read_string_to_list(category_and_product_response)\n",
    "    if debug: print(\"Step 2: Extracted list of products.\")\n",
    "    product_information = utils.generate_output_string(category_and_product_list)\n",
    "    if debug: print(\"Step 3: Looked up product information.\")\n",
    "    system_message = f\"\"\"\n",
    "    You are a customer service assistant for a large electronic store. \\\n",
    "    Respond in a friendly and helpful tone, with concise answers. \\\n",
    "    Make sure to ask the user relevant follow-up questions.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': f\"{delimiter}{user_input}{delimiter}\"},\n",
    "        {'role': 'assistant', 'content': f\"Relevant product information:\\n{product_information}\"}\n",
    "    ]\n",
    "    final_response = get_completion_from_messages(all_messages + messages)\n",
    "    if debug:print(\"Step 4: Generated response to user question.\")\n",
    "    all_messages = all_messages + messages[1:]\n",
    "    response = openai.Moderation.create(input=final_response)\n",
    "    moderation_output = response[\"results\"][0]\n",
    "    if moderation_output[\"flagged\"]:\n",
    "        if debug: print(\"Step 5: Response flagged by Moderation API.\")\n",
    "        return \"Sorry, we cannot provide this information.\"\n",
    "    if debug: print(\"Step 5: Response passed moderation check.\")\n",
    "    user_message = f\"\"\"\n",
    "    Customer message: {delimiter}{user_input}{delimiter}\n",
    "    Agent response: {delimiter}{final_response}{delimiter}\n",
    "    Does the response sufficiently answer the question?\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': user_message}\n",
    "    ]\n",
    "    evaluation_response = get_completion_from_messages(messages)\n",
    "    if debug: print(\"Step 6: Model evaluated the response.\")\n",
    "    if \"Y\" in evaluation_response:  # Using \"in\" instead of \"==\" to be safer for model output variation (e.g., \"Y.\" or \"Yes\")\n",
    "        if debug: print(\"Step 7: Model approved the response.\")\n",
    "        return final_response, all_messages\n",
    "    else:\n",
    "        if debug: print(\"Step 7: Model disapproved the response.\")\n",
    "        neg_str = \"I'm unable to provide the information you're looking for. I'll connect you with a human representative for further assistance.\"\n",
    "        return neg_str, all_messages\n",
    "\n",
    "user_input = \"tell me about the smartx pro phone and the fotosnap camera, the dslr one. Also what tell me about your tvs\"\n",
    "response,_ = process_user_message(user_input,[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that collects user and assistant messages over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panel as pn\n",
    "\n",
    "# Initialize an empty list for messages\n",
    "panels = []\n",
    "\n",
    "def collect_messages(debug=False):\n",
    "    user_input = input(\"Enter your message: \")  # Simulating inp\n",
    "    if debug: print(f\"User Input = {user_input}\")\n",
    "    \n",
    "    if user_input == \"\":\n",
    "        return\n",
    "    \n",
    "    global context\n",
    "    response, context = process_user_message(user_input, context, debug=False)\n",
    "    \n",
    "    # Add user and assistant's messages to the panels\n",
    "    panels.append(pn.Row('User:', pn.pane.Markdown(user_input, width=600)))\n",
    "    panels.append(pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    "    \n",
    "    return pn.Column(*panels)\n",
    "\n",
    "# Call the function\n",
    "collect_messages(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat with the chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panels = [] # collect display \n",
    "context = [ {'role':'system', 'content':\"You are Service Assistant\"} ]  \n",
    "inp = pn.widgets.TextInput( placeholder='Enter text hereâ€¦')\n",
    "button_conversation = pn.widgets.Button(name=\"Service Assistant\")\n",
    "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "dashboard = pn.Column(\n",
    "    inp,\n",
    "    pn.Row(button_conversation),\n",
    "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    ")\n",
    "dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "print(dir(utils))  # Lists all functions and attributes in the utils module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products_and_category = utils.get_products_and_category()\n",
    "products_and_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find relevant product and category names (version 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_category_and_product_v1(user_input,products_and_category):\n",
    "\n",
    "    delimiter = \"####\"\n",
    "    system_message = f\"\"\"\n",
    "    You will be provided with customer service queries. \\\n",
    "    The customer service query will be delimited with {delimiter} characters.\n",
    "    Output a python list of json objects, where each object has the following format:\n",
    "        'category': <one of Computers and Laptops, Smartphones and Accessories, Televisions and Home Theater Systems, \\\n",
    "    Gaming Consoles and Accessories, Audio Equipment, Cameras and Camcorders>,\n",
    "    AND\n",
    "        'products': <a list of products that must be found in the allowed products below>\n",
    "\n",
    "\n",
    "    Where the categories and products must be found in the customer service query.\n",
    "    If a product is mentioned, it must be associated with the correct category in the allowed products list below.\n",
    "    If no products or categories are found, output an empty list.\n",
    "    \n",
    "\n",
    "    List out all products that are relevant to the customer service query based on how closely it relates\n",
    "    to the product name and product category.\n",
    "    Do not assume, from the name of the product, any features or attributes such as relative quality or price.\n",
    "\n",
    "    The allowed products are provided in JSON format.\n",
    "    The keys of each item represent the category.\n",
    "    The values of each item is a list of products that are within that category.\n",
    "    Allowed products: {products_and_category}\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    few_shot_user_1 = \"\"\"I want the most expensive computer.\"\"\"\n",
    "    few_shot_assistant_1 = \"\"\" \n",
    "    [{'category': 'Computers and Laptops', \\\n",
    "'products': ['TechPro Ultrabook', 'BlueWave Gaming Laptop', 'PowerLite Convertible', 'TechPro Desktop', 'BlueWave Chromebook']}]\n",
    "    \"\"\"\n",
    "    \n",
    "    messages =  [  \n",
    "    {'role':'system', 'content': system_message},    \n",
    "    {'role':'user', 'content': f\"{delimiter}{few_shot_user_1}{delimiter}\"},  \n",
    "    {'role':'assistant', 'content': few_shot_assistant_1 },\n",
    "    {'role':'user', 'content': f\"{delimiter}{user_input}{delimiter}\"},  \n",
    "    ] \n",
    "    return get_completion_from_messages(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate on some queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg_0 = f\"\"\"Which TV can I buy if I'm on a budget?\"\"\"\n",
    "\n",
    "products_by_category_0 = find_category_and_product_v1(customer_msg_0,\n",
    "                                                      products_and_category)\n",
    "print(products_by_category_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg_1 = f\"\"\"I need a charger for my smartphone\"\"\"\n",
    "\n",
    "products_by_category_1 = find_category_and_product_v1(customer_msg_1,\n",
    "                                                      products_and_category)\n",
    "print(products_by_category_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg_2 = f\"\"\"\n",
    "What computers do you have?\"\"\"\n",
    "\n",
    "products_by_category_2 = find_category_and_product_v1(customer_msg_2,\n",
    "                                                      products_and_category)\n",
    "products_by_category_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg_3 = f\"\"\"\n",
    "tell me about the smartx pro phone and the fotosnap camera, the dslr one.\n",
    "Also, what TVs do you have?\"\"\"\n",
    "\n",
    "products_by_category_3 = find_category_and_product_v1(customer_msg_3,\n",
    "                                                      products_and_category)\n",
    "print(products_by_category_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harder test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg_4 = f\"\"\"\n",
    "tell me about the CineView TV, the 8K one, Gamesphere console, the X one.\n",
    "I'm on a budget, what computers do you have?\"\"\"\n",
    "\n",
    "products_by_category_4 = find_category_and_product_v1(customer_msg_4,\n",
    "                                                      products_and_category)\n",
    "print(products_by_category_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the prompt to work on the hard test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_category_and_product_v2(user_input,products_and_category):\n",
    "    \"\"\"\n",
    "    Added: Do not output any additional text that is not in JSON format.\n",
    "    Added a second example (for few-shot prompting) where user asks for \n",
    "    the cheapest computer. In both few-shot examples, the shown response \n",
    "    is the full list of products in JSON only.\n",
    "    \"\"\"\n",
    "    delimiter = \"####\"\n",
    "    system_message = f\"\"\"\n",
    "    You will be provided with customer service queries. \\\n",
    "    The customer service query will be delimited with {delimiter} characters.\n",
    "    Output a python list of json objects, where each object has the following format:\n",
    "        'category': <one of Computers and Laptops, Smartphones and Accessories, Televisions and Home Theater Systems, \\\n",
    "    Gaming Consoles and Accessories, Audio Equipment, Cameras and Camcorders>,\n",
    "    AND\n",
    "        'products': <a list of products that must be found in the allowed products below>\n",
    "    Do not output any additional text that is not in JSON format.\n",
    "    Do not write any explanatory text after outputting the requested JSON.\n",
    "\n",
    "\n",
    "    Where the categories and products must be found in the customer service query.\n",
    "    If a product is mentioned, it must be associated with the correct category in the allowed products list below.\n",
    "    If no products or categories are found, output an empty list.\n",
    "    \n",
    "\n",
    "    List out all products that are relevant to the customer service query based on how closely it relates\n",
    "    to the product name and product category.\n",
    "    Do not assume, from the name of the product, any features or attributes such as relative quality or price.\n",
    "\n",
    "    The allowed products are provided in JSON format.\n",
    "    The keys of each item represent the category.\n",
    "    The values of each item is a list of products that are within that category.\n",
    "    Allowed products: {products_and_category}\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    few_shot_user_1 = \"\"\"I want the most expensive computer. What do you recommend?\"\"\"\n",
    "    few_shot_assistant_1 = \"\"\" \n",
    "    [{'category': 'Computers and Laptops', \\\n",
    "'products': ['TechPro Ultrabook', 'BlueWave Gaming Laptop', 'PowerLite Convertible', 'TechPro Desktop', 'BlueWave Chromebook']}]\n",
    "    \"\"\"\n",
    "    \n",
    "    few_shot_user_2 = \"\"\"I want the most cheapest computer. What do you recommend?\"\"\"\n",
    "    few_shot_assistant_2 = \"\"\" \n",
    "    [{'category': 'Computers and Laptops', \\\n",
    "'products': ['TechPro Ultrabook', 'BlueWave Gaming Laptop', 'PowerLite Convertible', 'TechPro Desktop', 'BlueWave Chromebook']}]\n",
    "    \"\"\"\n",
    "    \n",
    "    messages =  [  \n",
    "    {'role':'system', 'content': system_message},    \n",
    "    {'role':'user', 'content': f\"{delimiter}{few_shot_user_1}{delimiter}\"},  \n",
    "    {'role':'assistant', 'content': few_shot_assistant_1 },\n",
    "    {'role':'user', 'content': f\"{delimiter}{few_shot_user_2}{delimiter}\"},  \n",
    "    {'role':'assistant', 'content': few_shot_assistant_2 },\n",
    "    {'role':'user', 'content': f\"{delimiter}{user_input}{delimiter}\"},  \n",
    "    ] \n",
    "    return get_completion_from_messages(messages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the modified prompt on the hard tests cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg_3 = f\"\"\"\n",
    "tell me about the smartx pro phone and the fotosnap camera, the dslr one.\n",
    "Also, what TVs do you have?\"\"\"\n",
    "\n",
    "products_by_category_3 = find_category_and_product_v2(customer_msg_3,\n",
    "                                                      products_and_category)\n",
    "print(products_by_category_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression testing: verify that the model still works on previous test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg_0 = f\"\"\"Which TV can I buy if I'm on a budget?\"\"\"\n",
    "\n",
    "products_by_category_0 = find_category_and_product_v2(customer_msg_0,\n",
    "                                                      products_and_category)\n",
    "print(products_by_category_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather development set for automated testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_ideal_pairs_set = [\n",
    "    \n",
    "    # eg 0\n",
    "    {'customer_msg':\"\"\"Which TV can I buy if I'm on a budget?\"\"\",\n",
    "     'ideal_answer':{\n",
    "        'Televisions and Home Theater Systems':set(\n",
    "            ['CineView 4K TV', 'SoundMax Home Theater', 'CineView 8K TV', 'SoundMax Soundbar', 'CineView OLED TV']\n",
    "        )}\n",
    "    },\n",
    "\n",
    "    # eg 1\n",
    "    {'customer_msg':\"\"\"I need a charger for my smartphone\"\"\",\n",
    "     'ideal_answer':{\n",
    "        'Smartphones and Accessories':set(\n",
    "            ['MobiTech PowerCase', 'MobiTech Wireless Charger', 'SmartX EarBuds']\n",
    "        )}\n",
    "    },\n",
    "    # eg 2\n",
    "    {'customer_msg':f\"\"\"What computers do you have?\"\"\",\n",
    "     'ideal_answer':{\n",
    "           'Computers and Laptops':set(\n",
    "               ['TechPro Ultrabook', 'BlueWave Gaming Laptop', 'PowerLite Convertible', 'TechPro Desktop', 'BlueWave Chromebook'\n",
    "               ])\n",
    "                }\n",
    "    },\n",
    "\n",
    "    # eg 3\n",
    "    {'customer_msg':f\"\"\"tell me about the smartx pro phone and \\\n",
    "    the fotosnap camera, the dslr one.\\\n",
    "    Also, what TVs do you have?\"\"\",\n",
    "     'ideal_answer':{\n",
    "        'Smartphones and Accessories':set(\n",
    "            ['SmartX ProPhone']),\n",
    "        'Cameras and Camcorders':set(\n",
    "            ['FotoSnap DSLR Camera']),\n",
    "        'Televisions and Home Theater Systems':set(\n",
    "            ['CineView 4K TV', 'SoundMax Home Theater','CineView 8K TV', 'SoundMax Soundbar', 'CineView OLED TV'])\n",
    "        }\n",
    "    }, \n",
    "    \n",
    "    # eg 4\n",
    "    {'customer_msg':\"\"\"tell me about the CineView TV, the 8K one, Gamesphere console, the X one.\n",
    "I'm on a budget, what computers do you have?\"\"\",\n",
    "     'ideal_answer':{\n",
    "        'Televisions and Home Theater Systems':set(\n",
    "            ['CineView 8K TV']),\n",
    "        'Gaming Consoles and Accessories':set(\n",
    "            ['GameSphere X']),\n",
    "        'Computers and Laptops':set(\n",
    "            ['TechPro Ultrabook', 'BlueWave Gaming Laptop', 'PowerLite Convertible', 'TechPro Desktop', 'BlueWave Chromebook'])\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # eg 5\n",
    "    {'customer_msg':f\"\"\"What smartphones do you have?\"\"\",\n",
    "     'ideal_answer':{\n",
    "           'Smartphones and Accessories':set(\n",
    "               ['SmartX ProPhone', 'MobiTech PowerCase', 'SmartX MiniPhone', 'MobiTech Wireless Charger', 'SmartX EarBuds'\n",
    "               ])\n",
    "                    }\n",
    "    },\n",
    "    # eg 6\n",
    "    {'customer_msg':f\"\"\"I'm on a budget.  Can you recommend some smartphones to me?\"\"\",\n",
    "     'ideal_answer':{\n",
    "        'Smartphones and Accessories':set(\n",
    "            ['SmartX EarBuds', 'SmartX MiniPhone', 'MobiTech PowerCase', 'SmartX ProPhone', 'MobiTech Wireless Charger']\n",
    "        )}\n",
    "    },\n",
    "\n",
    "    # eg 7 # this will output a subset of the ideal answer\n",
    "    {'customer_msg':f\"\"\"What Gaming consoles would be good for my friend who is into racing games?\"\"\",\n",
    "     'ideal_answer':{\n",
    "        'Gaming Consoles and Accessories':set([\n",
    "            'GameSphere X',\n",
    "            'ProGamer Controller',\n",
    "            'GameSphere Y',\n",
    "            'ProGamer Racing Wheel',\n",
    "            'GameSphere VR Headset'\n",
    "     ])}\n",
    "    },\n",
    "    # eg 8\n",
    "    {'customer_msg':f\"\"\"What could be a good present for my videographer friend?\"\"\",\n",
    "     'ideal_answer': {\n",
    "        'Cameras and Camcorders':set([\n",
    "        'FotoSnap DSLR Camera', 'ActionCam 4K', 'FotoSnap Mirrorless Camera', 'ZoomMaster Camcorder', 'FotoSnap Instant Camera'\n",
    "        ])}\n",
    "    },\n",
    "    \n",
    "    # eg 9\n",
    "    {'customer_msg':f\"\"\"I would like a hot tub time machine.\"\"\",\n",
    "     'ideal_answer': []\n",
    "    }\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate test cases by comparing to the ideal answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def eval_response_with_ideal(response,\n",
    "                              ideal,\n",
    "                              debug=False):\n",
    "    \n",
    "    if debug:\n",
    "        print(\"response\")\n",
    "        print(response)\n",
    "    \n",
    "    # json.loads() expects double quotes, not single quotes\n",
    "    json_like_str = response.replace(\"'\",'\"')\n",
    "    \n",
    "    # parse into a list of dictionaries\n",
    "    l_of_d = json.loads(json_like_str)\n",
    "    \n",
    "    # special case when response is empty list\n",
    "    if l_of_d == [] and ideal == []:\n",
    "        return 1\n",
    "    \n",
    "    # otherwise, response is empty \n",
    "    # or ideal should be empty, there's a mismatch\n",
    "    elif l_of_d == [] or ideal == []:\n",
    "        return 0\n",
    "    \n",
    "    correct = 0    \n",
    "    \n",
    "    if debug:\n",
    "        print(\"l_of_d is\")\n",
    "        print(l_of_d)\n",
    "    for d in l_of_d:\n",
    "\n",
    "        cat = d.get('category')\n",
    "        prod_l = d.get('products')\n",
    "        if cat and prod_l:\n",
    "            # convert list to set for comparison\n",
    "            prod_set = set(prod_l)\n",
    "            # get ideal set of products\n",
    "            ideal_cat = ideal.get(cat)\n",
    "            if ideal_cat:\n",
    "                prod_set_ideal = set(ideal.get(cat))\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"did not find category {cat} in ideal\")\n",
    "                    print(f\"ideal: {ideal}\")\n",
    "                continue\n",
    "                \n",
    "            if debug:\n",
    "                print(\"prod_set\\n\",prod_set)\n",
    "                print()\n",
    "                print(\"prod_set_ideal\\n\",prod_set_ideal)\n",
    "\n",
    "            if prod_set == prod_set_ideal:\n",
    "                if debug:\n",
    "                    print(\"correct\")\n",
    "                correct +=1\n",
    "            else:\n",
    "                print(\"incorrect\")\n",
    "                print(f\"prod_set: {prod_set}\")\n",
    "                print(f\"prod_set_ideal: {prod_set_ideal}\")\n",
    "                if prod_set <= prod_set_ideal:\n",
    "                    print(\"response is a subset of the ideal answer\")\n",
    "                elif prod_set >= prod_set_ideal:\n",
    "                    print(\"response is a superset of the ideal answer\")\n",
    "\n",
    "    # count correct over total number of items in list\n",
    "    pc_correct = correct / len(l_of_d)\n",
    "        \n",
    "    return pc_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Customer message: {msg_ideal_pairs_set[7][\"customer_msg\"]}')\n",
    "print(f'Ideal answer: {msg_ideal_pairs_set[7][\"ideal_answer\"]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = find_category_and_product_v2(msg_ideal_pairs_set[7][\"customer_msg\"],\n",
    "                                         products_and_category)\n",
    "print(f'Resonse: {response}')\n",
    "\n",
    "eval_response_with_ideal(response,\n",
    "                              msg_ideal_pairs_set[7][\"ideal_answer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run evaluation on all test cases and calculate the fraction of cases that are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note, this will not work if any of the api calls time out\n",
    "score_accum = 0\n",
    "for i, pair in enumerate(msg_ideal_pairs_set):\n",
    "    print(f\"example {i}\")\n",
    "    \n",
    "    customer_msg = pair['customer_msg']\n",
    "    ideal = pair['ideal_answer']\n",
    "    \n",
    "    # print(\"Customer message\",customer_msg)\n",
    "    # print(\"ideal:\",ideal)\n",
    "    response = find_category_and_product_v2(customer_msg,\n",
    "                                                      products_and_category)\n",
    "\n",
    "    \n",
    "    # print(\"products_by_category\",products_by_category)\n",
    "    score = eval_response_with_ideal(response,ideal,debug=False)\n",
    "    print(f\"{i}: {score}\")\n",
    "    score_accum += score\n",
    "    \n",
    "\n",
    "n_examples = len(msg_ideal_pairs_set)\n",
    "fraction_correct = score_accum / n_examples\n",
    "print(f\"Fraction correct out of {n_examples}: {fraction_correct}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run through the end-to-end system to answer the user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_msg = f\"\"\"\n",
    "tell me about the smartx pro phone and the fotosnap camera, the dslr one.\n",
    "Also, what TVs or TV related products do you have?\"\"\"\n",
    "\n",
    "products_by_category = utils.get_products_from_query(customer_msg)\n",
    "category_and_product_list = utils.read_string_to_list(products_by_category)\n",
    "product_info = utils.get_mentioned_product_info(category_and_product_list)\n",
    "assistant_answer = utils.answer_user_msg(user_msg=customer_msg,\n",
    "                                                   product_info=product_info)\n",
    "print(assistant_answer) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the LLM's answer to the user with a rubric, based on the extracted product information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_prod_info = {\n",
    "    'customer_msg': customer_msg,\n",
    "    'context': product_info\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_with_rubric(test_set, assistant_answer):\n",
    "\n",
    "    cust_msg = test_set['customer_msg']\n",
    "    context = test_set['context']\n",
    "    completion = assistant_answer\n",
    "    \n",
    "    system_message = \"\"\"\\\n",
    "    You are an assistant that evaluates how well the customer service agent \\\n",
    "    answers a user question by looking at the context that the customer service \\\n",
    "    agent is using to generate its response. \n",
    "    \"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\\\n",
    "You are evaluating a submitted answer to a question based on the context \\\n",
    "that the agent uses to answer the question.\n",
    "Here is the data:\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Question]: {cust_msg}\n",
    "    ************\n",
    "    [Context]: {context}\n",
    "    ************\n",
    "    [Submission]: {completion}\n",
    "    ************\n",
    "    [END DATA]\n",
    "\n",
    "Compare the factual content of the submitted answer with the context. \\\n",
    "Ignore any differences in style, grammar, or punctuation.\n",
    "Answer the following questions:\n",
    "    - Is the Assistant response based only on the context provided? (Y or N)\n",
    "    - Does the answer include information that is not provided in the context? (Y or N)\n",
    "    - Is there any disagreement between the response and the context? (Y or N)\n",
    "    - Count how many questions the user asked. (output a number)\n",
    "    - For each question that the user asked, is there a corresponding answer to it?\n",
    "      Question 1: (Y or N)\n",
    "      Question 2: (Y or N)\n",
    "      ...\n",
    "      Question N: (Y or N)\n",
    "    - Of the number of questions asked, how many of these questions were addressed by the answer? (output a number)\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': user_message}\n",
    "    ]\n",
    "\n",
    "    response = get_completion_from_messages(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_output = eval_with_rubric(cust_prod_info, assistant_answer)\n",
    "print(evaluation_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the LLM's answer to the user based on an \"ideal\" / \"expert\" (human generated) answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_ideal = {\n",
    "    'customer_msg': \"\"\"\\\n",
    "tell me about the smartx pro phone and the fotosnap camera, the dslr one.\n",
    "Also, what TVs or TV related products do you have?\"\"\",\n",
    "    'ideal_answer':\"\"\"\\\n",
    "Of course!  The SmartX ProPhone is a powerful \\\n",
    "smartphone with advanced camera features. \\\n",
    "For instance, it has a 12MP dual camera. \\\n",
    "Other features include 5G wireless and 128GB storage. \\\n",
    "It also has a 6.1-inch display.  The price is $899.99.\n",
    "\n",
    "The FotoSnap DSLR Camera is great for \\\n",
    "capturing stunning photos and videos. \\\n",
    "Some features include 1080p video, \\\n",
    "3-inch LCD, a 24.2MP sensor, \\\n",
    "and interchangeable lenses. \\\n",
    "The price is 599.99.\n",
    "\n",
    "For TVs and TV related products, we offer 3 TVs \\\n",
    "\n",
    "\n",
    "All TVs offer HDR and Smart TV.\n",
    "\n",
    "The CineView 4K TV has vibrant colors and smart features. \\\n",
    "Some of these features include a 55-inch display, \\\n",
    "'4K resolution. It's priced at 599.\n",
    "\n",
    "The CineView 8K TV is a stunning 8K TV. \\\n",
    "Some features include a 65-inch display and \\\n",
    "8K resolution.  It's priced at 2999.99\n",
    "\n",
    "The CineView OLED TV lets you experience vibrant colors. \\\n",
    "Some features include a 55-inch display and 4K resolution. \\\n",
    "It's priced at 1499.99.\n",
    "\n",
    "We also offer 2 home theater products, both which include bluetooth.\\\n",
    "The SoundMax Home Theater is a powerful home theater system for \\\n",
    "an immmersive audio experience.\n",
    "Its features include 5.1 channel, 1000W output, and wireless subwoofer.\n",
    "It's priced at 399.99.\n",
    "\n",
    "The SoundMax Soundbar is a sleek and powerful soundbar.\n",
    "It's features include 2.1 channel, 300W output, and wireless subwoofer.\n",
    "It's priced at 199.99\n",
    "\n",
    "Are there any questions additional you may have about these products \\\n",
    "that you mentioned here?\n",
    "Or may do you have other questions I can help you with?\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the LLM's response agrees with or disagrees with the expert answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_vs_ideal(test_set, assistant_answer):\n",
    "\n",
    "    cust_msg = test_set['customer_msg']\n",
    "    ideal = test_set['ideal_answer']\n",
    "    completion = assistant_answer\n",
    "    \n",
    "    system_message = \"\"\"\\\n",
    "    You are an assistant that evaluates how well the customer service agent \\\n",
    "    answers a user question by comparing the response to the ideal (expert) response\n",
    "    Output a single letter and nothing else. \n",
    "    \"\"\"\n",
    "\n",
    "    user_message = f\"\"\"\\\n",
    "You are comparing a submitted answer to an expert answer on a given question. Here is the data:\n",
    "    [BEGIN DATA]\n",
    "    ************\n",
    "    [Question]: {cust_msg}\n",
    "    ************\n",
    "    [Expert]: {ideal}\n",
    "    ************\n",
    "    [Submission]: {completion}\n",
    "    ************\n",
    "    [END DATA]\n",
    "\n",
    "Compare the factual content of the submitted answer with the expert answer. Ignore any differences in style, grammar, or punctuation.\n",
    "    The submitted answer may either be a subset or superset of the expert answer, or it may conflict with it. Determine which case applies. Answer the question by selecting one of the following options:\n",
    "    (A) The submitted answer is a subset of the expert answer and is fully consistent with it.\n",
    "    (B) The submitted answer is a superset of the expert answer and is fully consistent with it.\n",
    "    (C) The submitted answer contains all the same details as the expert answer.\n",
    "    (D) There is a disagreement between the submitted answer and the expert answer.\n",
    "    (E) The answers differ, but these differences don't matter from the perspective of factuality.\n",
    "  choice_strings: ABCDE\n",
    "\"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': system_message},\n",
    "        {'role': 'user', 'content': user_message}\n",
    "    ]\n",
    "\n",
    "    response = get_completion_from_messages(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assistant_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_vs_ideal(test_set_ideal, assistant_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant_answer_2 = \"life is like a box of chocolates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_vs_ideal(test_set_ideal, assistant_answer_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
